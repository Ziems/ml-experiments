{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Finder\n",
    "### By Noah Ziems\n",
    "\n",
    "Learning rates can be really hard to fine tune sometimes. If you're experimenting with new things, the last thing you want to do is worry whether your learning rate(lr for short) is wrong or not.\n",
    "\n",
    "To solve this problem, you can use a learning rate finding algorithm that tries out a bunch of different learning rates to see which seem to work best. These lr finding algorithms are purely emperical so by no means do they guarantee the ideal learning rate, but they seem to work pretty well in practice.\n",
    "\n",
    "For more, [here is a blog by Sylvain Gugger](https://sgugger.github.io/how-do-you-find-a-good-learning-rate.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports\n",
    "\n",
    "First we need to import everything we'll need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import math\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "Now let's setup our train and test dataset along with their respective dataloaders. I wont go into those here, as they aren't the focus of this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=32,\n",
    "                                          shuffle=True, num_workers=0)\n",
    "\n",
    "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=32,\n",
    "                                         shuffle=False, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Nerual Network\n",
    "\n",
    "Let's create a really basic convolutional neural network. Keep in mind that the learning rate finding algorithm should work with any architecture. I define the network then go ahead and create an instance of it and pop it on the GPU so I don't have to wait as long.\n",
    "\n",
    "[I stole this model from the PyTorch examples](https://pytorch.org/tutorials/beginner/blitz/cifar10_tutorial.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "net = Net()\n",
    "net = net.cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function and Optimizer\n",
    "\n",
    "The learning rate finder requires a loss function, optimizer, and a model to be already defined. Lets use Cross Entropy and Adam. Keep in mind that the learning rate finder is designed to work regardless of which loss function and optimizer you are using, just like the model above.\n",
    "\n",
    "It's also worth noting that you do not need to set a learning rate for the optimizer here because it gets overwritten by the learning rate finder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning Rate Finder\n",
    "\n",
    "Finally, after all that setup, we can get down to business. There is a lot of code here, but the idea is very simple. We start with a small learning rate, in this case `1e-7` and exponentially work our way up to a very large learning rate, in this case `10`, keeping track of the learning rates and losses along the way. Keep in mind that we are not linearly increasing the learning rate, as that would cause a higher concentrations of samples at larger lrs and lower concentrations at the smaller lrs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def find_lr(init_value=1e-7, final_value=10., beta = 0.98):\n",
    "    num = len(trainloader)-1\n",
    "    mult = (final_value / init_value)**(1/num)\n",
    "    lr = init_value\n",
    "    optimizer.param_groups[0]['lr'] = lr \n",
    "    avg_loss = 0.\n",
    "    best_loss = 0.\n",
    "    batch_num = 0\n",
    "    losses = []\n",
    "    log_lrs = []\n",
    "    \n",
    "    for i, data in enumerate(trainloader):\n",
    "        batch_num += 1\n",
    "        inputs, labels = data\n",
    "        inputs, labels = inputs.cuda(), labels.cuda()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = net(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        # Compute the smoothed loss\n",
    "        avg_loss = beta * avg_loss + (1-beta) * loss.item()\n",
    "        smoothed_loss = avg_loss / (1 - beta**batch_num)\n",
    "        # Stop if the loss is exploding\n",
    "        if batch_num > 1 and smoothed_loss > 4 * best_loss:\n",
    "            return log_lrs, losses\n",
    "        # Record the best loss\n",
    "        if smoothed_loss < best_loss or batch_num==1:\n",
    "            best_loss = smoothed_loss\n",
    "        # Store the values\n",
    "        losses.append(smoothed_loss)\n",
    "        log_lrs.append(math.log10(lr))\n",
    "        # Do the SGD step\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        # Update the lr for the next step\n",
    "        lr *= mult\n",
    "        optimizer.param_groups[0]['lr'] = lr\n",
    "    return log_lrs, losses\n",
    "\n",
    "log_lrs, losses = find_lr()\n",
    "plt.plot(log_lrs[10:-5], losses[10:-5])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading the Graph\n",
    "\n",
    "After we've plotted the learning rates(technically their logs) and their respective losses, its clear to see which learning rates have the best losses. However, emperically, a good learning rate is usually found in the middle of the steepest negative slope.\n",
    "\n",
    "In this case, it looks like the slope is negative between `-4` and `-2`, which means a good learning rate would be ~`1e-3`. Lets try it out for an epoch and see how it does!\n",
    "\n",
    "We need to reset the optimizer and network because they were changed in the process of finding the learning rate. After that we just train the model for an epoch. Note we set `lr=1e-3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "net = Net()\n",
    "net = net.cuda()\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=1e-3)\n",
    "\n",
    "def train(nb_epoch=1):\n",
    "    for epoch in range(nb_epoch):\n",
    "        for i, data in enumerate(trainloader):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = net(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "    print('Finished Training')\n",
    "    \n",
    "train(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How did we do after just one epoch? Keep in mind that baseline accuracy for CIFAR-10, the dataset we're using, is around 10%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the network on the 10000 test images: 49 %\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in testloader:\n",
    "            inputs, labels = data\n",
    "            inputs, labels = inputs.cuda(), labels.cuda()\n",
    "\n",
    "            outputs = net(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print('Accuracy of the network on the 10000 test images: %d %%' % (\n",
    "        100 * correct / total))\n",
    "    \n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at that! Our accuracy is way better than 10%! We've nailed it! Looks like the lr finding algorithm works and we read the graph correctly.\n",
    "\n",
    "Let's run it for a few more epochs to see how much better we can get it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Training\n",
      "Accuracy of the network on the 10000 test images: 64 %\n"
     ]
    }
   ],
   "source": [
    "train(10)\n",
    "test()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks great! Thanks for reading :D"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
