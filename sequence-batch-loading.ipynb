{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
    "from torch.nn import functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['well done is better than well said',\n",
       " 'better slip with foot than tongue',\n",
       " 'there never was a good war or a bad peace']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q1 = \"Well done is better than well said\".lower()\n",
    "q2 = \"Better slip with foot than tongue\".lower()\n",
    "q3 = \"There never was a good war or a bad peace\".lower()\n",
    "quotes = [q1, q2, q3]\n",
    "quotes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['take action instead of speaking',\n",
       " 'be very careful of what you say',\n",
       " 'war is never good and peace is never bad']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1 = \"Ben Franklin\".lower()\n",
    "s2 = \"Be very careful of what you say\".lower()\n",
    "s3 = \"War is never good and peace is never bad\".lower()\n",
    "sources = [s1, s2, s3]\n",
    "sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 25 unique characters\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['<pad>',\n",
       " '<eos>',\n",
       " '<unk>',\n",
       " 'e',\n",
       " 'd',\n",
       " 'y',\n",
       " 'i',\n",
       " 's',\n",
       " 'c',\n",
       " 't',\n",
       " 'u',\n",
       " 'o',\n",
       " 'v',\n",
       " 'a',\n",
       " 'w',\n",
       " 'n',\n",
       " 'r',\n",
       " 'h',\n",
       " 'l',\n",
       " 'k',\n",
       " 'p',\n",
       " ' ',\n",
       " 'b',\n",
       " 'g',\n",
       " 'f']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars = ['<pad>', '<eos>', '<unk>'] + list(set(' '.join(quotes + summaries)))\n",
    "nb_char = len(chars)\n",
    "\n",
    "print(f'There are {nb_char} unique characters')\n",
    "chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'<pad>': 0,\n",
       " '<eos>': 1,\n",
       " '<unk>': 2,\n",
       " 'e': 3,\n",
       " 'd': 4,\n",
       " 'y': 5,\n",
       " 'i': 6,\n",
       " 's': 7,\n",
       " 'c': 8,\n",
       " 't': 9,\n",
       " 'u': 10,\n",
       " 'o': 11,\n",
       " 'v': 12,\n",
       " 'a': 13,\n",
       " 'w': 14,\n",
       " 'n': 15,\n",
       " 'r': 16,\n",
       " 'h': 17,\n",
       " 'l': 18,\n",
       " 'k': 19,\n",
       " 'p': 20,\n",
       " ' ': 21,\n",
       " 'b': 22,\n",
       " 'g': 23,\n",
       " 'f': 24}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "char_to_ix = { ch:i for i,ch in enumerate(chars)}\n",
    "ix_to_char = { i:ch for i,ch in enumerate(chars)}\n",
    "\n",
    "char_to_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([34]),\n",
       " torch.Size([33]),\n",
       " torch.Size([41]),\n",
       " torch.Size([31]),\n",
       " torch.Size([31]),\n",
       " torch.Size([40])]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_seq = [torch.tensor(list(map(lambda char: char_to_ix[char], i))) for i in quotes + summaries]\n",
    "[x.shape for x in x_seq]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[torch.Size([41]),\n",
       " torch.Size([41]),\n",
       " torch.Size([41]),\n",
       " torch.Size([41]),\n",
       " torch.Size([41]),\n",
       " torch.Size([41])]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_padded = pad_sequence(x_seq, batch_first=True, padding_value=char_to_ix['<pad>'])\n",
    "[x.shape for x in x_padded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([14,  3, 18, 18, 21,  4, 11, 15,  3, 21,  6,  7, 21, 22,  3,  9,  9,  3,\n",
       "         16, 21,  9, 17, 13, 15, 21, 14,  3, 18, 18, 21,  7, 13,  6,  4]),\n",
       " tensor([ 9, 13, 19,  3, 21, 13,  8,  9,  6, 11, 15, 21,  6, 15,  7,  9,  3, 13,\n",
       "          4, 21, 11, 24, 21,  7, 20,  3, 13, 19,  6, 15, 23]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class BenFranklinSummaryDataset(Dataset):\n",
    "    \"\"\"Dataset for Summarizing Benjamin Franklin Quotes\"\"\"\n",
    "    \n",
    "    def __init__(self, quotes, summaries):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            quotes (list(string)): A list of quotes\n",
    "            summaries (list(string)): A list of summaries\n",
    "        \"\"\"\n",
    "        self.quotes = quotes\n",
    "        self.summaries = summaries\n",
    "        \n",
    "        assert len(quotes) == len(summaries), \"The number of quotes must match the number of summaries!\"\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(quotes)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        x_seq = torch.tensor(list(map(lambda char: char_to_ix[char], self.quotes[idx])))\n",
    "        y_seq = torch.tensor(list(map(lambda char: char_to_ix[char], self.summaries[idx])))\n",
    "            \n",
    "        return (x_seq, y_seq)\n",
    "    \n",
    "dset = BenFranklinSummaryDataset(quotes, summaries)\n",
    "dset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_collate(batch):\n",
    "    (xx, yy) = zip(*batch)\n",
    "    x_lens = [len(x) for x in xx]\n",
    "    y_lens = [len(y) for y in yy]\n",
    "\n",
    "    xx_pad = pad_sequence(xx, batch_first=True, padding_value=0)\n",
    "    yy_pad = pad_sequence(yy, batch_first=True, padding_value=0)\n",
    "    \n",
    "    return xx_pad, yy_pad, x_lens, y_lens\n",
    "\n",
    "dataset = BenFranklinSummaryDataset(quotes, summaries)\n",
    "data_loader = DataLoader(dataset=dataset, batch_size=2, shuffle=True, collate_fn=pad_collate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 41, 100])\n",
      "torch.Size([1, 33, 100])\n"
     ]
    }
   ],
   "source": [
    "embedding = nn.Embedding(nb_char, 100)\n",
    "for i,(x_padded, y_padded, x_lens, y_lens) in enumerate(data_loader):\n",
    "    x_embed = embedding(x_padded)\n",
    "    print(x_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(RNN, self).__init__()\n",
    "        embedding_dim = 100\n",
    "        hidden_size = 100\n",
    "        \n",
    "        self.embedding = nn.Embedding(nb_char, embedding_dim)\n",
    "        self.gru = nn.GRU(embedding_dim, hidden_size, batch_first=True)\n",
    "        self.fc_out = nn.Linear(hidden_size, nb_char)\n",
    "        \n",
    "    def forward(self, x, x_lens):\n",
    "        x_embed = self.embedding(x)\n",
    "        x_packed = pack_padded_sequence(x_embed, x_lens, batch_first=True, enforce_sorted=False)\n",
    "        output_packed, hidden = self.gru(x_packed)\n",
    "        output_padded, output_lengths = pad_packed_sequence(output_packed, batch_first=True)\n",
    "        output = self.fc_out(output_padded)\n",
    "        return output\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([34, 25])\n",
      "torch.Size([2, 31])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Expected input batch_size (34) to match target batch_size (31).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-312d092d761e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mbatch_ce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m         \u001b[0mce_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcross_entropy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_padded\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sum\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m         \u001b[0mbatch_ce_loss\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mce_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"Batch Cross Entropy Loss: {batch_ce_lossce_loss}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   2019\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2020\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2021\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlog_softmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2022\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2023\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mnll_loss\u001b[0;34m(input, target, weight, size_average, ignore_index, reduce, reduction)\u001b[0m\n\u001b[1;32m   1834\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1835\u001b[0m         raise ValueError('Expected input batch_size ({}) to match target batch_size ({}).'\n\u001b[0;32m-> 1836\u001b[0;31m                          .format(input.size(0), target.size(0)))\n\u001b[0m\u001b[1;32m   1837\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1838\u001b[0m         \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnll_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input batch_size (34) to match target batch_size (31)."
     ]
    }
   ],
   "source": [
    "rnn = RNN()\n",
    "for i,(x_padded, y_padded, x_lens, y_lens) in enumerate(data_loader):\n",
    "    # This whole section below probably belongs in its own model\n",
    "    output = rnn(x_padded, x_lens)\n",
    "    print(output[0].shape)\n",
    "    print(y_padded.shape)\n",
    "    \n",
    "    batch_ce_loss = 0.0\n",
    "    for i in range(output.size(0)):\n",
    "        ce_loss = F.cross_entropy(output[i], y_padded[i], reduction=\"sum\", ignore_index=0)\n",
    "        batch_ce_loss += ce_loss\n",
    "    print(f\"Batch Cross Entropy Loss: {batch_ce_lossce_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
